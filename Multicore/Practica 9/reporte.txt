= Práctica #9: Resolviendo problemas con OpenMP
:author: Diego Galíndez Barreda (A01370815), Eduardo Blatzuri Gaytán Martinez (A01165988)
:lang: es
:email: dgalindez1@gmail.com, A01165988@itesm.mx 
:encoding: utf-8
:revdate: 6 de noviembre, 2015.
:source-highlighter: coderay
:numbered:

Este reporte fue elaborado para el curso de _Programación multinúcleo_ del Tecnológico de Monterrey, Campus Estado de México.  

:numbered:

== Introducción
Durante la práctica se utiliza la funcionalidad que otorga OpenMP en C para
implementar programas en paralelo.
Se hace una aproximación al valor de PI con el método de Montecarlo y se hace un
Counting Sort, ambos de forma secuencial y con pragmas de omp para hacerlos en
paralelo.

[NOTE]
.Hardware y software utilizado
=============================
Los programas se probaron en una laptop con las siguientes características:

- Procesador Intel Core i5-4200U de 1.60GHz con dos núcleos y cuatro hyperthreads.
- 5.7 GiB de memoria RAM.
- Sistema operativo Ubuntu 14.04, kernel de Linux 3.19.0-25 de 64 bits.
- Compilador GCC 5.2
=============================

== Solución de Montecarlo
A continuación se anexa el codigo fuente de la solución para aproximar PI con el
método de Montecarlo, usando 100,000,000 coordenadas aleatorias.
Se realizaron ambas soluciones dentro del mismo programa y estas se ejecutan de
froma secuencial.

[source, c]
----------------------------
include::MonteCarlo.c[]
----------------------------

Se muestra la aproximación obtenida por cada método, así como el tiempo que
tomó ejecutar cada uno.
En ninguno de los dos casos se está considerando el tiempo de inicialización de
ninguna de las variables usadas.
Se usan números aleatorios en el rango de -1 y 1, de forma que no necesitamos
obtener la raíz del número como se haría tradicionalmente por el teorema de
pitágoras. Esto hace más eficiente el programa en general y simplifica el
código.

A continuación está la salida del programa:

[source,text]
----------------------------
Sequential pi = 3.14154992
Sequential time: 2.3111 sec.
Parallel pi = 3.13443036
Parallel time: 3.2811 sec.
----------------------------

== Resultados de las soluciones de Montecarlo
A continuación mostramos varias corridas de ambos programas:

.Tiempos de ejecución de la aproximación secuencial 
[options="header,footer", cols="^,^", width="70%"]
|=======================
| # de corrida     | Tiempo T~1~ (segundos)
| 1                | 2.311
| 2                | 2.284
| 3                | 2.303
| 4                | 2.307
| 5                | 2.309
| Media aritmética | 2.302
|=======================

.Tiempos de ejecución de la aproximación en paralelo 
[options="header,footer", cols="^,^", width="70%"]
|=======================
| # de corrida     | Tiempo T~2~ (segundos)
| 1                | 3.281
| 2                | 3.288
| 3                | 3.263
| 4                | 3.242
| 5                | 3.259
| Media aritmética | 3.266
|=======================

El speedup es de: 0.7X

Podemos ver que el programa concurrente es de hecho más lento que el programa
secuencial. Es posible que esto se deba a la función de rand_r, ya que esta está
hecha para ser thread safe y es posible que esté bloqueando la ejecución (con
algún tipo de seguro o semáforo) y esto provoca que la ejecución en paralelo sea
más lenta, por la espera para el seguro además del overhead provocado por la
creación y sincronización de los diferentes hilos.

A pesar de esto, el programa demuestra que pasar de la implementación secuencial
(con algoritmos similares a este) a la paralela, resulta casi trivial y, si el
sistema no tuviera soporte para OpenMP, la solución paralela se ejecutaría
extactamente igual que la secuencial.

Esto último representa una gran ventaja, porque permite que el sistema siga
en uso aunque llegue a tener cambios que provoquen problemas de compatibilidad.

Pese a ello, podemos afirmar que para este caso en particular no es conveniente
usar la solución paralela, ya que es menos precisa y más lenta. Si hubiera
alguna forma más eficiente de generar los números aleatorios, tal vez resultaría
mejor.

== Solución Counting Sort
A continuación se anexa el codigo fuente de la solución para hacer un Counting
Sort. En este caso se hicieron tanto la solución secuencial como la paralela
dentro del mismo programa, de forma que se pueda usar el mismo arreglo y en el
mismo orden. Esto se lleva a cabo con un generador de números pseudo aleatorios,
al cual se le da la misma semilla para ambos casos.

Se usó un arreglo con 100,000 números aleatorios.

[source, c]
----------------------------
include::CountingSort.c[]
----------------------------

Se muestra si el arreglo sobre el que se va a ejecutar el ordenamiento está ya
ordenado o no. Después se realiza el ordenamiento y se revisa si ya está
ordenado y se da el tiempo de ejecución. Esto se hace para cada versión, de
forma que se pueden comparar fácilmente los tiempos y verificar que sí funciona
el algoritmo de forma correcta en ambos casos.

El tiempo de ejecución no incluye la generación de los números ni el llenado del
arreglo. Tampoco incluye el tiempo que toma revisar si el arreglo está ordenado
o no, solamente se toma el tiempo que tarda el algoritmo de ordenamiento.

A continuación está la salida del programa:

[source,text]
----------------------------
Array is sorted: No 
Array is sorted: Yes 
Sequential time: 64.2468
Array is sorted: No 
Array is sorted: Yes 
Parallel time: 31.5477
----------------------------

== Resultados de las soluciones de CountingSort 
A continuación mostramos varias corridas del programa, separando los tiempos en
sequencial y en paralelo:

.Tiempos de ejecución de la aproximación secuencial 
[options="header,footer", cols="^,^", width="70%"]
|=======================
| # de corrida     | Tiempo T~1~ (segundos)
| 1                | 64.2468
| 2                | 64.1975
| 3                | 64.2401
| 4                | 64.2255
| 5                | 64.2304
| Media aritmética | 64.2281
|=======================

.Tiempos de ejecución de la aproximación en paralelo 
[options="header,footer", cols="^,^", width="70%"]
|=======================
| # de corrida     | Tiempo T~2~ (segundos)
| 1                | 31.5477
| 2                | 31.0390
| 3                | 31.5025
| 4                | 31.6101
| 5                | 31.5218
| Media aritmética | 31.4442
|=======================

El speedup es de: 2.04X

Se puede observar un aumento bastante significativo en la solución paralela,
obivamente obteniendo los mismos resultados, esto es que el arreglo queda en
orden. En este caso es un aumento considerable ya que se reduce un algoritmo de
O(N^2^) a un O(N) si es que se cuentan con tantos hilos como elementos a
ordenar.

A pesar de que este no es el caso ya que se usaron 100,000 elementos, seguimos
observando un aumento muy bueno en el tiempo de ejecución. Reduce el tiempo
aproximadamente a la mitad.

Al igual que con el método de Montecarlo podemos ver que la solución paralela no
resulta tan compleja de impelmentar, de hecho es muy sencilla ya que solo se
requiere agregar las directivas adecuadas y los resultados son bastante
eficientes. 

En este caso es innegable la ventaja de usar la versión paralela, ya que tiene
los mismos resultados que la secuencial en la mitad del tiempo.
